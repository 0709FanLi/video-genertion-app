工具草案

### 1. 产品概述

**1.1 产品愿景**
打造一个基于Python技术栈的一体化、模块化、高自由度的下一代AI创意生成平台，让创作者能够通过自然语言和视觉参考，无缝地在图像与视频两种媒介间进行创作和迭代，释放无限的想象力。

**1.2 核心价值**
*   **一体化工作流：** 将文生图、图生视频、视频扩展三个核心AI能力整合在一个平台内，实现无缝衔接的创作体验。
*   **模块化设计：** 每个功能模块均可独立使用，满足用户在不同场景下的单一需求，同时支持串联形成复杂工作流。
*   **智能化辅助：** 提供提示词优化、图片内容自动分析生成描述等AI辅助功能，降低用户使用门槛。
*   **精细化控制：** 提供参考图、首尾帧、模型选择等多种控制手段，让用户不仅"能生成"，更能"精雕细琢"。
*   **模型自由：** 支持接入和切换多种底层大模型，适应不同风格、质量和成本的需求。

### 2. 目标用户
*   **概念设计师 & 艺术导演**
*   **营销与广告从业者**

### 3. 核心功能详述

#### 3.1 模块一：文字生成图片

**功能目标：** 根据用户输入的文字提示词，生成高质量的图片，并支持对提示词进行优化和通过参考图控制风格。

**用户流程与交互细节：**
1.  **输入主提示词：** 用户在主文本框中输入想要生成图片的描述。
2.  **（可选）文字优化：**
    *   系统提供一个"优化提示词"的复选框或按钮。
    *   点击后，展开一个下拉菜单，列出可用的优化大模型（如 GPT-4, Claude, 文心一言等），并有一个标记为"系统默认"的选项。
    *   选择模型后，系统将用户的原提示词发送给该模型，返回一个或多个优化后的、更详细、更具表现力的提示词版本供用户选择。
3.  **（可选）上传参考图：**
    *   提供"上传参考图"区域，支持拖拽或点击上传。
    *   **关键细节（已简化）：** 支持多图上传（例如最多4张）。**移除了每张图的权重滑块和复杂的融合模式选择**。系统将平等地参考所有上传的图片风格，或采用一种内置的默认融合逻辑。
    *   用户可以通过拖拽调整参考图的顺序，排在第一位的图片可能会被系统视为主要参考。
4.  **选择图片生成模型：** 提供一个下拉菜单，选择文生图模型（如 Stable Diffusion XL, DALL-E 3, Midjourney API, 国内各类模型等），并设有平台推荐的"默认模型"。
5.  **生成与输出：**
    *   点击"生成"按钮，进入任务队列。
    *   生成结果以网格形式展示（如默认4宫格）。
    *   用户可对单张结果进行：**"下载"**、**"设为参考图"**（一键存入参考图库）、**"用于视频生成"**（一键进入模块2，并将此图作为素材）。

---

#### 3.2 模块二：图片生成视频

**功能目标：** 以用户提供的图片为基础，生成一段短视频。支持单图首帧、双图首尾帧插值，并**新增通过图片分析自动生成视频提示词的功能**。

**用户流程与交互细节：**
1.  **图片输入：**
    *   用户从本地上传或直接从"模块一"的结果中"拖入"图片。
    *   界面提供两个明确的"区域"：**"首帧"** 和 **"尾帧"**。
2.  **模式选择：**
    *   **单图模式：** 将图片放入"首帧"区域。"尾帧"区域显示提示"可选"。系统将根据单图内容和提示词生成一段有动态变化的视频。
    *   **首尾帧模式：** 将一张图放入"首帧"，另一张放入"尾帧"。
        *   **关键细节：** 两个区域之间有一个 **"交换"按钮**，点击后可快速切换首尾帧的顺序，从而改变视频的演变方向。
3.  **输入视频提示词：**
    *   **方式一（手动输入）：** 用户直接在文本框中描述希望视频中发生什么样的运动或变化（如："镜头拉远"、"花瓣飘落"）。
    *   **方式二（智能分析）：**
        *   在提示词输入框旁增加一个 **"分析图片"** 的按钮。
        *   用户上传或选择一张图片后，点击此按钮。
        *   系统调用视觉理解大模型（如GPT-4V, LLaVA等）对该图片进行分析，生成一段详细的、描述性的文本。
        *   生成的描述会自动填充到视频提示词输入框中，用户可在此基础上进行修改和精炼，使其更符合视频动态化的需求。
        *   **应用场景：** 此功能特别适用于用户有一张风格参考图但不知如何用文字描述，或希望视频内容与某张图片高度一致的场景。
4.  **选择视频生成模型：** 下拉菜单选择视频模型（如 Sora, Stable Video Diffusion, Gen-2, Pika等），并设有"默认模型"。
5.  **视频参数设置（高级选项）：**
    *   **时长：** 滑动选择视频秒数（如3秒，4秒，5秒）。
    *   **分辨率：** 选择输出视频的分辨率（如 720p, 1080p）。
    *   **运动强度：** 滑块控制视频中动态效果的剧烈程度。
6.  **生成与输出：**
    *   点击"生成视频"。
    *   生成完成后，提供视频预览、下载功能。
    *   提供 **"扩展此视频"** 按钮，一键进入模块3，并将当前视频作为素材。

---

#### 3.3 模块三：视频扩展

**功能目标：** 对已有视频进行时间线上的延长或空间画幅上的扩展。

**用户流程与交互细节：**
1.  **视频输入：** 上传本地视频或从"模块二"的结果中直接导入。
2.  **扩展模式选择：**
    *   **时间扩展：** 延长视频的播放时长（例如，让3秒视频变为6秒）。
        *   **方向：** 选择向前扩展（生成视频的开头部分）或向后扩展（生成视频的结尾部分）。
    *   **空间扩展：** 扩大视频的画布（例如，将16：9的视频扩展为更宽的视角，类似"图片外绘"）。
    *   **混合扩展：** 同时进行时间和空间扩展。
3.  **扩展提示词：**
    *   **默认扩展：** 系统自动分析原视频内容，智能推测并生成扩展部分的提示词，用户可直接使用。
    *   **自定义扩展：** 用户手动输入，精确控制扩展部分的内容和风格。例如，在时间向后扩展时输入"然后，一朵花绽放了"。
4.  **选择视频扩展模型：** 下拉菜单选择专门用于视频扩展的模型（可能部分模型与模块2通用，但需明确标注其扩展能力）。
5.  **生成与输出：** 生成新的扩展后视频，并提供下载。扩展后的视频可再次被扩展，形成迭代。


### 5. 未来迭代方向
1.  **音频集成：** 为视频一键生成背景音乐或音效。
2.  **高级编辑：** 内置简单的视频剪辑功能（裁剪、拼接、加字幕）。
3.  **社区与模板：** 建立用户社区，分享优秀作品和生成工作流模板。
4.  **自定义模型训练：** 允许用户上传自己的数据集，微调生成风格。
5.  **存储升级：** 当用户量和文件量增长后，平滑迁移到云对象存储服务。